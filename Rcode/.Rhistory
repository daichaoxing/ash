# two-sided test
ttest.pval = function(t, df) {
pval = pt(t, df = df, lower.tail = T)
pval = 2 * ifelse(pval < 0.5, pval, 1 - pval)
return(pval)
}
tscore = zdat[3, ]/zdat[4, ]
pval = ttest.pval(tscore, df = 2)
qval = qvalue(pval)
highxp = xx>1000 # select high expressed genes
pval.high = pval[highxp]
qval.high = qvalue(pval.high)
cc.assoc.high = counts.associate(cc[highxp,],g,1)
zdat.ash.high = cc.assoc.high$zdat.ash
zdat.high = cc.assoc.high$zdat
seqData=newSeqCountSet(cc, g)
seqData=estNormFactors(seqData)
seqData=newSeqCountSet(cc, g)
counts1=matrix(rnbinom(300, mu=10, size=10), ncol=3)
counts2=matrix(rnbinom(300, mu=50, size=10), ncol=3)
X1=cbind(counts1, counts2) ## these are 100 DE genes
X2=matrix(rnbinom(11400, mu=10, size=10), ncol=6)
X=rbind(X1,X2)
designs=c(0,0,0,1,1,1)
seqData=newSeqCountSet(X, designs)
dim(X)
dim(cc)
dim(g)
g
seqData=newSeqCountSet(cc, g)
dim(designs)
cc
seqData=newSeqCountSet(as.matrix(cc), g)
seqData=newSeqCountSet(matrix(cc), g)
seqData=newSeqCountSet(matrix(cc), designs=g)
seqData=newSeqCountSet(matrix(cc,ncol=4), designs=g)
head(matrix(cc,ncol=4))
cc[1,]
cc=as.matrix(cc)
dim(cc)
seqData=newSeqCountSet(cc, designs=g)
newSeqCountSet
?newSeqCountSet
names(g)
names(g)=colnames(cc)
colnames(cc)
seqData=newSeqCountSet(cc, designs=g)
library("DSS")
names(g)=colnames(cc)
seqData=newSeqCountSet(as.matrix(cc), g)
seqData=estNormFactors(seqData)
seqData=estDispersion(seqData)
result=waldTest(seqData)
seqData
g
seqData=newSeqCountSet(as.matrix(cc), c(0,0,1,1))
designs=c(0,0,1,1)
names(designs)=colnames(cc)
seqData=newSeqCountSet(as.matrix(cc), designs)
seqData=estNormFactors(seqData)
seqData=estDispersion(seqData)
result=waldTest(seqData)
wadTest
waldTest
result=waldTest(seqData,0,1)
locfdr
?locfdr
head(result)
waldTest
normalizationFactor(seqData)
waldTest=edit(waldTest)
result=waldTest(seqData,0,1)
head(result)
z.dss=result$difExpr/result$std
plot(z.dss,tscore)
z.dss[result$geneIndex]=result$difExpr/result$std
plot(z.dss,tscore)
identify(z.dss,tscore)
x[c(4870,10433,18130),]
result[c(4870,10433,18130),]
plot(result$fdr)
sum(result$fdr<0.1)
sum(zdat.ash$fdr<0.1)
names(zdat.ash)
sum(zdat.ash$qvalue<0.1)
33493/67
334933/67
cbind(x[,1:5],pval,zdat.ash$localfdr)[c(15325,16123),]
zdat[19422,]
zdat[,19422]
zdat[,c(15325,16123)]
print(getwd())
setwd("~/Documents/git/ash/Rcode/")
library("qvalue")
library("lattice") #library for some of the plots
setwd("~/Documents/git/ash/Rcode/")
library("qvalue")
hh = read.table("../data/nejm_brca_release_edit.csv",sep=",",skip=3)
subset = apply(hh, 1, max)<20
hh = hh[subset,]
labs = read.table("../data/nejm_brca_release_edit.csv",sep=",",skip=1,nrows=1)
labs = 1*(labs=="BRCA1") + 2 * (labs=="BRCA2")
hh.betahat = apply(hh[,labs==1],1,mean) - apply(hh[,labs==2],1,mean)
n1 = sum(labs==1)
n2 = sum(labs==2)
hh.sebetahat = sqrt(apply(hh[,labs==1],1,var)/n1 + apply(hh[,labs==2],1,var)/n2)
hh.zscore = hh.betahat/hh.sebetahat
hh.pval = pchisq(hh.zscore^2,df=1,lower.tail=F)
hist(hh.pval,probability=TRUE,xlab="p value",main="Distribution of p values for Hedenfalk et al data",nclass=40,col=5)
hist(hh.zscore)
hist(hh.zscore,density=TRUE)
hist(hh.zscore,prob=TRUE)
hist(hh.zscore)
hist(hh.zscore,prob=TRUE)
tt = seq(-6,8,length=20)
tt = seq(-6,8,length=200)
lines(tt,dnorm(tt))
hist(hh.zscore,prob=TRUE,nclass=20)
lines(tt,dnorm(tt))
hist(hh.zscore,prob=TRUE,nclass=20,ylim=c(0,0.3))
lines(tt,dnorm(tt))
hist(hh.pval,probability=TRUE,xlab="p value",main="Distribution of p values for Hedenfalk et al data",nclass=40,col=5)
mu = c(rep(0,1000),rnorm(9000,-3,1))
z = mu+rnorm(10000)
hist(z)
zsim = mu+rnorm(10000)
zsim.ash=ash(zsim)
ash
zsim.ash=ash(zsim,1)
zsim.ash=ash(zsim,rep(1,10000)
)
mu = c(rnorm(1000,-3,1),rep(0,9000))
zsim = mu+rnorm(10000)
zsim.ash=ash(zsim,rep(1,10000))
names(zsim.ash)
plot(mu[1:1000],zsim[1:1000])
sum(zsim.ash$localfdr<0.05)
sum(zsim.ash$qvalue<0.05)
plot(zsim.ash$qvalue)
sum(zsim.ash$qvalue[1:1000]<0.05)
626/707
zsim.ash$fitted
mu = c(rnorm(1000,-3,1),rnorm(1000,-1.5,1),rep(0,9000))
zsim = mu+rnorm(10000)
mu = c(rnorm(1000,-3,1),rnorm(1000,-1.5,1),rep(0,8000))
zsim = mu+rnorm(10000)
zsim.ash=ash(zsim,rep(1,10000))
names(zsim.ash)
plot(mu[1:1000],zsim[1:1000])
sum(zsim.ash$qvalue[1:1000]<0.05)/sum(zsim.ash$qvalue<0.05)
sum(zsim.ash$qvalue[1:2000]<0.05)/sum(zsim.ash$qvalue<0.05)
hist(mu)
hist(mu[-(1:2000)])
hist(mu[1:2000])
mu = c(rnorm(1000,-3,1),rnorm(1000,0,1),rep(0,8000))
hist(mu[1:2000])
mu = c(rnorm(1000,-3,1),rnorm(1000,0,1),rnorm(1000,-1,1),rep(0,7000))
hist(mu[1:3000])
zsim = mu+rnorm(10000)
zsim.ash=ash(zsim,rep(1,10000))
names(zsim.ash)
plot(mu[1:1000],zsim[1:1000])
sum(zsim.ash$qvalue[1:3000]<0.05)/sum(zsim.ash$qvalue<0.05)
sum(zsim.ash$qvalue<0.05)
zsim.ash$qvalue[1:3000]<0.05)
sum(zsim.ash$qvalue[1:3000]<0.05)
plot(zsim.ash$qvalue, zsim.ash$localfdr)
1069-956
55/1069
mu = c(rnorm(1000,-3,1),rep(0,9000))
zsim = mu+rnorm(10000)
zsim.ash=ash(zsim,rep(1,10000))
plot(mu[1:1000],zsim[1:1000])
sum(0.5*(zsim.ash$qvalue[1000:10000]<0.05)/sum(zsim.ash$qvalue<0.05))
musim2 = c(rnorm(1000,-3,1),rnorm(1000,-1.5,1),rnorm(1000,0,1),rep(0,7000))
zsim2 = musim2+rnorm(10000)
zsim2.ash=ash(zsim2,rep(1,10000))
hist(musim2)
hist(musim2[1:3000])
sum(0.5*(zsim2.ash$qvalue[1000:10000]<0.05)/sum(zsim2.ash$qvalue<0.05))
sum(0.5*(zsim2.ash$qvalue[3000:10000]<0.05)/sum(zsim2.ash$qvalue<0.05))
errorinsign = ifelse(musim2==0,0.5,(zsim2.ash$PosteriorMean/musim2)<0)
errorinsign
sum(errorinsign[zsim2.ash$qvalue<0.05])/sum(zsim2.ash$qvalue<0.05)
names(zsim.ash)
zsim.ash$post
names(zsim.ash$post)
p(\hat\beta, s, \beta | \pi) & = \prod_j g(\beta_j ; \pi) p(\hat\beta_j, s_j | \beta_j) \\
#sigma rather than fixing it, but this not yet implemented.
setwd("~/Documents/git/ash/Rcode/")
## load Poisson_binomial and ash functions
source("../Rcode/ash.R")
musim = c(rnorm(1000,-3,1),rep(0,9000))
zsim = musim+rnorm(10000)
zsim.ash=ash(zsim,rep(1,10000))
setwd("~/Documents/git/ash/Rcode/")
## load Poisson_binomial and ash functions
source("../Rcode/ash.R")
beta = c(rnorm(1000,-3,1),rep(0,9000))
betahat = musim+rnorm(10000)
zsim.ash=ash(zsim,rep(1,10000))
beta = c(rnorm(1000,-3,1),rep(0,9000))
betahat = musim+rnorm(10000)
beta.ash=ash(betahat,rep(1,10000))
beta.ash$Post
plot(beta.ash$Post,beta)
source("../Rcode/ash.R")
beta = c(rnorm(1000,-3,1),rep(0,9000))
betahat = beta+rnorm(10000)
beta.ash=ash(betahat,rep(1,10000))
beta.ash$fitted
hist(beta)
hist(betahat)
hist(beta.ash$PosteriorMean)
plot(beta.ash$PosteriorMean,betahat)
set.seed
?set.seed
source("../Rcode/ash.R")
beta = c(rnorm(1000,-3,1),rep(0,9000))
betahat = beta+rnorm(10000)
beta.ash=ash(betahat,rep(1,10000))
plot(beta.ash$PosteriorMean,betahat)
plot(betahat,beta.ash$PosteriorMean,xlab="observed beta", ylab="Estimated beta (posterior mean)",ylim=-7,4),xlim=c(-7,4))
plot(betahat,beta.ash$PosteriorMean,xlab="observed beta", ylab="Estimated beta (posterior mean)",ylim=c(-7,4),xlim=c(-7,4))
abline(a=0,b=1,col=1)
abline(a=0,b=1,col=2)
abline(h=0)
setwd("~/Documents/git/ash/Rcode/")
set.seed(32327)
## load Poisson_binomial and ash functions
source("../Rcode/ash.R")
beta = c(rnorm(1000,-3,1),rep(0,9000))
s= rep(1,10000)
betahat = beta+rnorm(10000,beta,s)
beta.ash=ash(betahat,s)
#compute the usual zscore and corresponding p value
zscore = betahat/s
pval = pchisq(zscore^2,df=1,lower.tail=F)
plot(betahat,beta.ash$PosteriorMean,xlab="Observed betahat", ylab="Estimated beta (posterior mean)",ylim=c(-7,4),xlim=c(-7,4))
abline(h=0)
abline(a=0,b=1,col=2)
hist(pval)
plot(beta.ash$localfdr, pval)
hist(pval,nclass=1000)
plot(pval, beta)
library("qvalue")
zscore = betahat/s
pval = pchisq(zscore^2,df=1,lower.tail=F)
qval = qvalue(pval)
plot(qval$q,beta.ash$localfdr)
plot(qval$q,beta.ash$qval)
plot(qval$q,2*beta.ash$qval)
abline(a=0,b=1)
qval$pi0
cumsum(truenull[o])/(1:10000)
truenull = (rep(0,1000),rep(1,9000))
truenull = c(rep(0,1000),rep(1,9000))
cumsum(truenull[o])/(1:10000)
o = order(beta.ash$qval)
cumsum(truenull[o])/(1:10000)
plot(beta.ash$qval,cumsum(truenull[o])/(1:10000))
plot(beta.ash$qval[o],cumsum(truenull[o])/(1:10000))
plot(qval$qval[o],cumsum(truenull[o])/(1:10000),col=2)
plot(qval$qval[o],cumsum(truenull[o])/(1:10000),col=2)
lines(beta.ash$qval[o],cumsum(truenull[o])/(1:10000))
plot(qval$qval[o],cumsum(truenull[o])/(1:10000),col=2)
lines(beta.ash$qval[o],cumsum(truenull[o])/(1:10000))
plot(cumsum(truenull[o])/(1:10000),qval$qval[o],col=2)
lines(cumsum(truenull[o])/(1:10000),2*beta.ash$qval[o])
plot(cumsum(truenull[o])/(1:10000),qval$qval[o],col=2,type="l")
lines(cumsum(truenull[o])/(1:10000),2*beta.ash$qval[o])
abline(a=0,b=1)
pos= betahat>0
betapos.ash=ash(betahat[pos],s[pos])
betaneg.ash = ash(betahat[neg],s[neg])
betapos.ash=ash(betahat[pos],s[pos])
betaneg.ash = ash(betahat[!pos],s[!pos])
lfdr[pos] = betapos.ash$lfdr
lfdr = rep(0,length(betahat))
lfdr[pos] = betapos.ash$lfdr
lfdr[!pos] = betaneg.ash$lfdr
lfdr = rep(0,length(betahat))
lfdr[pos] = betapos.ash$localfdr
lfdr[!pos] = betaneg.ash$localfdr
lfdr
plot(lfdr,zscore)
plot(lfdr,pval)
}else{
source("../Rcode/ash.R")
qv = qvalue.from.localfdr(lfdr)
qv = qval.from.localfdr(lfdr)
plot(qv,beta.ash$qval)
o = order(qv)
o = order(qv)
plot(cumsum(truenull[o])/(1:10000),2*qv[o],type="l")
abline(a=0,b=1)
hist(beta)
truenull = c(rep(0,1000),rep(1,9000))
beta = c(rnorm(1000,-3,1),rep(0,9000))
s= rep(1,10000)
truenull = c(rep(0,2000),rep(1,8000))
beta = c(rnorm(1000,-3,1),rnorm(1000,-1.5,1),rep(0,9000))
s= rep(1,10000)
betahat = beta+rnorm(10000,beta,s)
beta.ash=ash(betahat,s)
#compute the usual zscore and corresponding p value
zscore = betahat/s
beta = c(rnorm(1000,-3,1),rnorm(1000,-1.5,1),rep(0,8000))
s= rep(1,10000)
betahat = beta+rnorm(10000,beta,s)
beta.ash=ash(betahat,s)
#compute the usual zscore and corresponding p value
zscore = betahat/s
pval = pchisq(zscore^2,df=1,lower.tail=F)
qval = qvalue(pval)
plot(qval$q,2*beta.ash$qval,main="comparison of ash and q value qvalues")
abline(a=0,b=1)
o = order(beta.ash$qval)
plot(cumsum(truenull[o])/(1:10000),qval$qval[o],col=2,type="l")
lines(cumsum(truenull[o])/(1:10000),2*beta.ash$qval[o])
abline(a=0,b=1)
hist(betatrue)
hist(beta)
truenull = c(rep(0,2000),rep(1,8000))
beta = c(rnorm(1000,-3,1),rnorm(1000,-1.5,1),rep(0,8000))
hist(beta)
setwd("~/Documents/git/ash/Rcode/")
set.seed(32327)
## load ash functions
source("../Rcode/ash.R")
library("qvalue")
```
```{r}
betahat = rnorm(1000,0,1)
sd = rep(1000,1)
betahat[1]=4
hist(betahat)
betahat.ash = ash(betahat,sd)
ash
sd = rep(1,1000)
betahat[1]=4
hist(betahat)
betahat.ash = ash(betahat,sd)
betahat.ash$fitted.f
plot(betahat.ash$PosteriorMean,betahat)
betahat.ash2=ash(betahat,sd,prior="uniform")
betahat.ash2$fitted.f
plot(betahat.ash2$PosteriorMean,betahat)
betahat.ash2=ash(betahat,sd,prior=rep(2,13))
betahat.ash2=ash(betahat,sd,prior=rep(2,12))
betahat.ash2=ash(betahat,sd,prior=rep(2,16))
betahat.ash2$fitted.f
betahat.ash3=ash(betahat,sd,prior=rep(1,16))
betahat.ash3$fitted.f
plot(betahat.ash3$PosteriorMean,betahat,)
betahat.ash3=ash(betahat,sd,prior=rep(4,16))
betahat.ash3$fitted.f
betahat.ash3=ash(betahat,sd,prior=rep(1000,16))
betahat.ash3$fitted.f
betahat.ash3=ash(betahat,sd,prior=2
)
betahat.ash3$fitted.f
betahat.ash3$loglik
names(betahat.ash3)
betahat.ash3$fit
source("../Rcode/ash.R")
betahat.ash3=ash(betahat,sd,prior=rep(1000,16))
betahat.ash3$fitted.f
betahat.ash3=ash(betahat,sd,prior=rep(1000,16),nullcheck=FALSE)
betahat.ash3$fitted.f
ash
source("../Rcode/ash.R")
ash
setwd("~/Documents/git/ash/Rcode/")
set.seed(32327)
## load ash functions
source("../Rcode/ash.R")
ash
source('~/Documents/git/ash/Rcode/ash.R')
EMfit
ash
source("../Rcode/ash.R")
betahat.ash3=ash(betahat,sd,prior=rep(1000,16),nullcheck=FALSE)
betahat.ash3$fitted.f
betahat.ash3=ash(betahat,sd,prior=2,nullcheck=FALSE)
betahat.ash3$fitted.f
plot(betahat.ash3$PosteriorMean,betahat,)
citation()
betahat = rnorm(100,0,1)
sebetahat = rep(1,100)
sigmaavec = c(0.1,1,5,10)
EMest = function(betahat,sebetahat,sigmaavec,pi,sigma.est=FALSE,nullcheck=TRUE,prior=NULL,nc=NULL,VB=FALSE,ltol=0.0001, maxiter=5000){
if(!is.null(nc)&sigma.est==TRUE){
sigmaavec=2^(seq(-15,3,length.out=nc))
}
k=length(sigmaavec)
n = length(betahat)
sigmamin=min(sigmaavec)
sigmamax=max(sigmaavec)
null.comp = which.min(sigmaavec) #which component is the "null"
if(is.null(prior)){ # set up prior to be 1,1/(k-1),...,1/(k-1) to favour "null"
prior = rep(1/(k-1),k)
prior[null.comp] = 1
}else if(prior=="uniform"){
prior = rep(1,k)
}
abf = matrixABF(betahat,sebetahat,sigmaavec)
if(VB==TRUE){
F1 = rep(0,maxiter)
pipost = prior # Dirichlet posterior on pi
dnorm.mat = matrix(dnorm(rep(betahat,each=k), rep(0,k*n), sd=sqrt(rep(sebetahat^2,each=k)+rep(sigmaavec^2,n))),ncol=k,byrow=TRUE)
avgpipost = matrix(exp(digamma(rep(pipost,n))-digamma(rep(sum(pipost),k*n))),ncol=k,byrow=TRUE)
classprob = avgpipost * dnorm.mat
classprob = classprob/rowSums(classprob) # n by k matrix
priorSum = sum(prior)
pipostSum = sum(pipost)
F1[1] = sum(classprob*log(avgpipost*dnorm.mat)) - diriKL(prior,pipost) #negative free energy
for(i in 2:maxiter){
pipost = colSums(classprob) + prior
#Now re-estimate pipost
avgpipost = matrix(exp(rep(digamma(pipost,n))-rep(digamma(sum(pipost)),k*n)),ncol=k,byrow=TRUE)
classprob = avgpipost*dnorm.mat
classprob = classprob/rowSums(classprob) # n by k matrix
priorSum = sum(prior)
pipostSum = sum(pipost)
F1[i] = sum(classprob*log(avgpipost*dnorm.mat)) - diriKL(prior,pipost)
if(abs(F1[i]-F1[i-1])<ltol) break;
}
pi = pipost/sum(pipost) # use posterior mean to estimate pi
m  = t(pi * t(abf)) # abf is n by k; so this is also n by k
m.rowsum = rowSums(m)
loglik.final = sum(log(m.rowsum))
null.loglik = sum(log(abf[,null.comp]))
loglik = F1 # actually return F1 not log-likelihood!
}else{
loglik = rep(0,maxiter)
m  = t(pi * t(abf)) # abf is n by k; so this is also n by k
m.rowsum = rowSums(m)
loglik[1] = sum(log(m.rowsum))
classprob = m/m.rowsum #an n by k matrix
for(i in 2:maxiter){
pi = colSums(classprob) + prior-1
pi = ifelse(pi<0,0,pi) #set any estimates that are less than zero, which can happen with prior<1, to 0
pi = normalize(pi)
#estimate sigma
if(sigma.est==TRUE){
for(j in 1:k){
pj=classprob[,j]
f=function(x) sum((betahat^2/(sebetahat^2+x)^2-1/(sebetahat^2+x))*pj)
if(f(sigmamin^2)<=0){
sigmaavec[j]=sigmamin
}else if(f(sigmamax^2)>=0){
sigmaavec[j]=sigmamax
}else{
sigmaavec[j]=sqrt(uniroot(f,c(sigmamin^2,sigmamax^2))$root)
}
}
abf = matrixABF(betahat,sebetahat,sigmaavec)
}
#Now re-estimate pi
m  = t(pi * t(abf))
m.rowsum = rowSums(m)
loglik[i] = sum(log(m.rowsum))
classprob = m/m.rowsum
if(abs(loglik[i]-loglik[i-1])<ltol) break;
}
null.loglik = sum(log(abf[,null.comp]))
loglik.final = loglik[i]
}
if(nullcheck==TRUE){
if(null.loglik > loglik.final){ #check whether exceeded "null" likelihood where everything is null
pi=rep(0,k)
pi[null.comp]=1
m  = t(pi * t(abf))
m.rowsum = rowSums(m)
loglik[i] = sum(log(m.rowsum))
classprob = m/m.rowsum
}
}
return(list(pi=pi,classprob=classprob,sigmaavec=sigmaavec,loglik=loglik[1:i],null.loglik=null.loglik,
abf=abf,niter=i, converged = (i<maxiter), temp1=sum(log(abf[,null.comp])),temp2=loglik.final))
}
EMest(betahat,sebetahat,sigmaavec,VB=T)
setwd("/Volumes/PERSONAL/MS/ash/Rcode")
source('ash.R')
setwd("/Volumes/PERSONAL/MS/ash/Rcode")
EMest(betahat,sebetahat,sigmaavec,VB=T)
source('ash.R')
source('ash.R')
EMest(betahat,sebetahat,sigmaavec,VB=T)
sebetahat = rep(1,10000)
betahat = rnorm(10000,0,1)
EMest(betahat,sebetahat,sigmaavec,VB=T)
EMest(betahat,sebetahat,sigmaavec,VB=TRUE)
temp.vb=EMest(betahat,sebetahat,sigmaavec,VB=TRUE)
temp=EMest(betahat,sebetahat,sigmaavec,VB=FALSE)
EMest
temp=EMest(betahat,sebetahat,sigmaavec,pi=rep(1,length(sigmaavec)),VB=FALSE)
names(temp)
temp$pi
temp.vb$pi
temp=EMest(betahat[1:2],sebetahat[1:2],sigmaavec,pi=rep(1,length(sigmaavec)),VB=FALSE)
temp.vb=EMest(betahat[1:2],sebetahat[1:2],sigmaavec,pi=rep(1,length(sigmaavec)),VB=TRUE)
temp.vb2=EMest(betahat[1:2],sebetahat[1:2],sigmaavec,pi=rep(1,length(sigmaavec)),VB=TRUE,prior="uniform")
temp$pi
temp.vb$pi
temp.vb2$pi
temp.vb2=EMest(betahat[1:2],sebetahat[1:2],sigmaavec,pi=rep(1,length(sigmaavec)),VB=TRUE,prior="uniform",null.check=FALSE)
temp.vb2=EMest(betahat[1:2],sebetahat[1:2],sigmaavec,pi=rep(1,length(sigmaavec)),VB=TRUE,prior="uniform",nullcheck=FALSE)
temp.vb2$pi
temp.vb=EMest(betahat[1:2],sebetahat[1:2],sigmaavec,pi=rep(1,length(sigmaavec)),VB=TRUE,nullcheck=FALSE)
temp.vb$pi
