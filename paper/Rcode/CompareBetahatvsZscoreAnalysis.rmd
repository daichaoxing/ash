---
title: "CompareBetahatvsZscoreAnalysis"
output: html_document
---

The ashr package implements a shrinkage-based Empirical Bayes
method for estimating the values of effects $\beta_j$ based
on estimates of the effects ($\hat\beta_j$) and their standard errors ($s_j$).

A key modelling assumption is that the effects $\beta_j$ are identically distributed
from a unimodal distribution $g$. 
In particular, ashr assumes that $\beta_j$ is independent of the standard error $s_j$.
That is,
$$\beta_j | s_j \sim g(\cdot).$$

Here we consider an alternative modelling assumption:
$$\beta_j/s_j | s_j \sim g(\cdot).$$
Under this alternative assumption
the *standardized effects* $\beta_j/s_j$ are identically distributed from a unimodal
distribution. Under this assumption the expected size of the *unstandardized* effect $\beta_j$ depends on the standard error $s_j$: the larger $s_j$ is, the larger (in absolute value) $\beta_j$ is expected to be. 

What might motivate this alternative assumption? 
We can provide two distinct motivations. First, suppose for concreteness that the effects
$\beta_j$ reflect differences in gene expression between two conditions. One factor that affects
$s_j$ is the variance of gene $j$ within each condition. One could imagine that genes with a larger variance within each condition are less tightly regulated, and therefore more likely to show a large difference between conditions (i.e. large $\beta_j$) than genes with a small variance. This provides
a biological motivation for the possibility that larger $s_j$ might 
correlate with larger $\beta_j$ (although of course not for the exact functional form above).
A second motivation is more statistical: it turns out that this assumption is in some sense
the implicit assumption made by existing methods to fdr analysis based on p values. 
More specifically, under this alternative assumption, when 
attempting to identify ``significant" effects, the empirical Bayes approach will rank the genes 
in the same way as the usual $p$ values computed from $\hat\beta_j/s_j$.

It is straightforward to use the ashr package to perform analysis under this alternative model:
one simply replaces betahat with the standardized betahat, $\hat\beta_j$, and the standard errors
for these standarized betahat values with 1. It is also straightforward to compare
the two competing modelling assumptions by computing the log likelihood ratio, $log[p_1(\hat\beta | s, \hat g_1)/p_2(\hat\beta | s, \hat g_2)]$, where $p_1$ denotes the default ash model,
and $p_2$ denotes the alternative model discussed here.

Let's illustrate by a simulated example. We assume that the standard errors come
from a gamma distribution, and then generate the effects $\beta_j$ under the alternative assumption so that genes with bigger standard errors tend to have bigger effects.
```{r}
  set.seed(1234)
  nsamp=1000
  betahat.se = rgamma(nsamp,1,1)
  beta = betahat.se * rnorm(nsamp) #simulate effects under the alternative assumption 
  betahat = rnorm(nsamp,beta,betahat.se)
  zscore = betahat/betahat.se
  pval = pchisq(zscore^2,df=1,lower.tail=FALSE)
  plot(betahat, -log(pval))
```

Here is the standard ash analysis.
```{r}
  library(ashr)
  ash1.res = ash(betahat, betahat.se,method="fdr")
```

And here is how we can perform the analysis under the alternative model,
by replacing betahat with the standardized betahat, and replacing the standard error with 1:
```{r}
  ash2.res = ash(betahat/betahat.se, 1,method="fdr")
```


```{r}
  loglik1=ashr:::loglik.ash(ash1.res, betahat, betahat.se, zscore=FALSE) 
  loglik2=ashr:::loglik.ash(ash2.res,betahat, betahat.se, zscore=TRUE)
  loglik1-loglik2
```

Then the log likelihood ratio is loglik1-loglik2=-93.9. This highly negative
loglikelihood indicate that the data strongly favor 
the alternative model 2, which is expected because the data were generated under this model.
(One might be tempted to ask whether the log likelihood ratio is ``significant". We don't 
know how to address this question, but suggest in practice it doesn't matter: if the loglikelihood ratio is positive then use the default analysis, if it is negative then use the alternative analysis.)

To finish, we illustrate that if we generate data under the original model then that model
is preferred by the log likelihood:
```{r}
  set.seed(1234)
  nsamp=1000
  betahat.se = rgamma(nsamp,1,1)
  beta = rnorm(nsamp) #simulate effects under the original assumption 
  betahat = rnorm(nsamp,beta,betahat.se)
  zscore = betahat/betahat.se
  pval = pchisq(zscore^2,df=1,lower.tail=FALSE)
  ash1.res = ash(betahat, betahat.se,method="fdr")
  ash2.res = ash(betahat/betahat.se, 1,method="fdr")
  loglik1=ashr:::loglik.ash(ash1.res, betahat, betahat.se, zscore=FALSE) 
  loglik2=ashr:::loglik.ash(ash2.res,betahat, betahat.se, zscore=TRUE)
  loglik1-loglik2
```


