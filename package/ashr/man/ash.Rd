% Generated by roxygen2 (4.0.2): do not edit by hand
\name{ash}
\alias{ash}
\title{Main Adaptive SHrinkage function}
\usage{
ash(betahat, sebetahat, method = c("shrink", "fdr"),
  mixcompdist = c("uniform", "halfuniform", "normal"), lambda1 = 1,
  lambda2 = 0, nullcheck = TRUE, df = NULL, randomstart = FALSE,
  nullweight = 10, nonzeromean = FALSE, pointmass = FALSE,
  onlylogLR = FALSE, prior = c("uniform", "nullbiased"), mixsd = NULL,
  VB = FALSE, gridmult = sqrt(2), minimaloutput = FALSE,
  multiseqoutput = FALSE, g = NULL, maxiter = 5000, cxx = FALSE)
}
\arguments{
\item{betahat}{a p vector of estimates}

\item{sebetahat}{a p vector of corresponding standard errors}

\item{method}{specifies how ash is to be run. Can be "shrinkage" (if main aim is shrinkage) or "fdr" (if main aim is to assess fdr or fsr)
This is simply a convenient way to specify certain combinations of parameters: "shrinkage" sets pointmass=FALSE and prior="uniform";
"fdr" sets pointmass=TRUE and prior="nullbiased".}

\item{mixcompdist}{distribution of components in mixture ( "uniform","halfuniform" or "normal"), the default value would be "uniform"}

\item{lambda1}{multiplicative "inflation factor" for standard errors (like Genomic Control)}

\item{lambda2}{additive "inflation factor" for standard errors (like Genomic Control)}

\item{nullcheck}{whether to check that any fitted model exceeds the "null" likelihood
in which all weight is on the first component}

\item{df}{appropriate degrees of freedom for (t) distribution of betahat/sebetahat, default is NULL(Gaussian)}

\item{randomstart}{logical, indicating whether to initialize EM randomly. If FALSE, then initializes to prior mean (for EM algorithm) or prior (for VBEM)}

\item{nullweight}{scalar, the weight put on the prior under "nullbiased" specification, see \code{prior}}

\item{nonzeromean}{logical, indicating whether to use a nonzero mean unimodal mixture(defaults to "FALSE")}

\item{pointmass}{logical, indicating whether to use a point mass at zero as one of components for a mixture distribution}

\item{onlylogLR}{logical, indicating whether to use this function to get logLR. Skip posterior prob, posterior mean, lfdr...}

\item{prior}{string, or numeric vector indicating Dirichlet prior on mixture proportions (defaults to "uniform", or (1,1...,1); also can be "nullbiased" (nullweight,1,...,1) to put more weight on first component)}

\item{mixsd}{vector of sds for underlying mixture components}

\item{VB}{whether to use Variational Bayes to estimate mixture proportions (instead of EM to find MAP estimate), see \code{\link{mixVBEM}} and \code{\link{mixEM}}}

\item{gridmult}{the multiplier by which the default grid values for mixsd differ by one another. (Smaller values produce finer grids)}

\item{g}{the prior distribution for beta (usually estimated from the data; this is used primarily in simulated data to do computations with the "true" g)}

\item{maxiter}{maximum number of iterations of the EM algorithm}

\item{cxx}{flag to indicate whether to use the c++ (Rcpp) version. After application of Squared extrapolation methods for accelerating fixed-point iterations (R Package "SQUAREM"), the c++ version is no longer faster than non-c++ version, thus we do not recommend using this one, and might be removed at any point.}

\item{minimal_output}{if TRUE, just outputs the fitted g and the lfsr (useful for very big data sets where memory is an issue)}
}
\value{
ash returns an object of \code{\link[base]{class}} "ash", a list with the following elements(or a  simplified list, if \eqn{onlylogLR=TRUE}, \eqn{minimaloutput=TRUE}   or \eqn{multiseqoutput=TRUE}) \cr
\item{fitted.g}{fitted mixture, either a normalmix or unimix}
\item{logLR}{logP(D|mle(pi)) - logP(D|null)}
\item{PosteriorMean}{A vector consisting the posterior mean of beta from the mixture}
\item{PosteriorSD}{A vector consisting the corresponding posterior standard deviation}
\item{PositiveProb}{A vector of posterior probability that beta is positive}
\item{NegativeProb}{A vector of posterior probability that beta is negative}
\item{ZeroProb}{A vector of posterior probability that beta is zero}
\item{lfsr}{The local false sign rate}
\item{lfsra}{The local false sign rate(adjusted)}
\item{lfdr}{A vector of estimated local false discovery rate}
\item{qvalue}{A vector of q values given estimated local false discovery rates, and estimate of (tail) False Discovery Rate}
\item{fit}{The fitted mixture object by \code{\link{mixEM}} or \code{\link{mixVBEM}} }
\item{lambda1}{multiplicative "inflation factor"}
\item{lambda2}{additive "inflation factor"}
\item{call}{a call in which all of the specified arguments are specified by their full names}
\item{data}{a list consisting the input betahat and sebetahat}
\item{df}{the specified degrees of freedom for (t) distribution of betahat/sebetahat}
}
\description{
Takes vectors of estimates (betahat) and their standard errors (sebetahat), and applies
shrinkage to them, using Empirical Bayes methods, to compute shrunk estimates for beta.
}
\details{
See readme for more details
}
\examples{
beta = c(rep(0,100),rnorm(100))
sebetahat = abs(rnorm(200,0,1))
betahat = rnorm(200,beta,sebetahat)
beta.ash = ash(betahat, sebetahat)
summary(beta.ash)
plot(betahat,beta.ash$PosteriorMean,xlim=c(-4,4),ylim=c(-4,4))

betahat=betahat+1000
beta.ash = ash(betahat, sebetahat)
summary(beta.ash)
plot(betahat,beta.ash$PosteriorMean)
}

