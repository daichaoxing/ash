peakwidth = rep(50,npeak)
mu = 100*(rowSums(matDens(1:J,peakcenters,peakwidth)) + 0.002)
x = rpois(J,mu)
plot(mu,type="l",xlab="base",ylab="intensity",ylim=c(0,max(mu)),main="Poisson intensity")
abline(v=peakcenters,col="red")
plot(x, main="Simulated Poisson data")
set.seed(100)
library("mixfdr") # I use the function matDens to compute mixture density
J = 2^10
npeak = 5
peakcenters = sample(1:J,5,replace=F)
peakwidth = rep(50,npeak)
mu = 100*(rowSums(matDens(1:J,peakcenters,peakwidth)) + 0.002)
x = rpois(J,mu)
plot(mu,type="l",xlab="base",ylab="intensity",ylim=c(0,max(mu)),main="Poisson intensity")
abline(v=peakcenters,col="red")
plot(x, main="Simulated Poisson data")
dwt(x)
dwt(x,fast=FALSE)
system.time(dwt(x))
dim(x)
length(x)
J = 2^20
npeak = 5
peakcenters = sample(1:J,5,replace=F)
peakwidth = rep(50,npeak)
mu = 100*(rowSums(matDens(1:J,peakcenters,peakwidth)) + 0.002)
x = rpois(J,mu)
plot(mu,type="l",xlab="base",ylab="intensity",ylim=c(0,max(mu)),main="Poisson intensity")
abline(v=peakcenters,col="red")
plot(x, main="Simulated Poisson data")
dim(x)
length(x)
system.time(dwt(x))
source("~/Documents/teaching/Workshop2013/stat45800/code/Rcode/PoissonBinomial.funcs.R")
haar.aggregate
system.time(haar.aggregate(x))
system.time(dwt(x))
dwt
J = 2^20
J = 2^10
bintest.haar
bintest
x=0
p=10000
n=1000
niter=100
beta.sd=1 #effect size
sdz = rep(0,niter)
sdzminusb = rep(0,niter)
sdz0= sdz
niter=1
x = matrix(rbinom(n*p,2,0.2),ncol=p)
x = scale(x,scale=FALSE) #center
xx = apply(x,2,sd)
x = t(t(x)/xx) # standardize by column root-mean-square
x[1,] %*% x[,1]
x[1,] * x[,1]
sum(x[1,] * x[,1])
sum(x[1,] * x[1,])
sum(x[,1] * x[,1])
sqrt(mean(y.lm$betahat^2))
beta = rnorm(p,mean=0,sd=beta.sd/sqrt(p))
#beta[1:10]=c(-1,-1,-1,-1,-1,1,1,1,1,1)
Ey = x %*% beta
E = rnorm(n,0,1) #error term
#sd(Ey) #check it should be close to beta.sd
y = Ey + E
y.lm = linreg(y,x)
y.ash = ash(y.lm$betahat,y.lm$sebetahat)
y.ash.pm = ash(y.lm$betahat,y.lm$sebetahat,usePointMass=TRUE)
linreg = function(y,x){
SX2 = colSums(x*x) #a p vector of sums of squares
betahat = as.vector(SX2^{-1} * (t(x) %*% y)) # a p vector
resid = as.vector(y) - t(t(x)*betahat)  # residuals, n by g
sigmahat = sqrt(colMeans(resid*resid)) # g vector, estimated residual variances
sebetahat = SX2^{-0.5} * sigmahat
return(list(betahat=betahat,sebetahat=sebetahat))
}
require("ashr")
y.lm = linreg(y,x)
y.ash = ash(y.lm$betahat,y.lm$sebetahat)
y.ash.pm = ash(y.lm$betahat,y.lm$sebetahat,usePointMass=TRUE)
plot(y.ash$PosteriorMean,beta)
plot(y.lm$betahat,beta)
sqrt(mean((y.lm$betahat-beta)^2)) #root mean square error of raw beta-hat
sqrt(mean((y.ash$PosteriorMean-beta)^2))
sqrt(mean(beta^2))
sqrt(mean(y.lm$betahat^2))
sqrt(1/1000)
mean(y.lm$betahat^2)
n
var(y)
var(Ey)
var(E)
sqrt(mean((y.lm$betahat-beta)^2)) #root mean square error of raw beta-hat
sqrt(var(y)/n)
x = t(t(x)/xx) # standardize by column root-mean-square
sd(x[,1])
sum(x[,1]^2)
x = scale(x,scale=FALSE) #center
xx = apply(x,2,sd)
x = t(t(x)/xx) # standardize by column root-mean-square
sum(x[,1]^2)
mean(x[,1]^2)
n=100
nrep=10000
rho=0.2
X1 = matrix(rnorm(n*nrep),ncol=nrep)
X2 = 0.2*X1 + 0.8*matrix(rnorm(n*nrep),ncol=nrep)
cor(X1[,1],X2[,1])
cor(X1[,2],X2[,2])
cor(X1[,3],X2[,3])
cor(X1[,4],X2[,4])
X1 = matrix(rnorm(n*nrep),ncol=nrep)
X2 = 0.2*X1 + 0.8*matrix(rnorm(n*nrep),ncol=nrep)
Y = X1+X2+ matrix(rnorm(n*nrep),ncol=nrep)
Z1 = t(X1) %*% Y
Z2 = t(X2) %*% Y
dim(Z1)
Z1 = apply(X1*Y, 1, sum)
length(Z1)
Z2 = apply(X2*Y,2,sum)
Z1 = apply(X1*Y, 2, sum)
Z2 = apply(X2*Y,2,sum)
cor(Z1,Z2)
X1 = matrix(rnorm(n*nrep),ncol=nrep)
X2 = 0.2*X1 + 0.8*matrix(rnorm(n*nrep),ncol=nrep)
Y = X1+X2+ 100*matrix(rnorm(n*nrep),ncol=nrep)
Z1 = apply(X1*Y, 2, sum)
Z2 = apply(X2*Y,2,sum)
cor(Z1,Z2)
n=1000
nrep=10000
rho=0.2
X1 = matrix(rnorm(n*nrep),ncol=nrep)
X2 = 0.2*X1 + 0.8*matrix(rnorm(n*nrep),ncol=nrep)
Y = X1+X2+ 100*matrix(rnorm(n*nrep),ncol=nrep)
Z1 = apply(X1*Y, 2, sum)
Z2 = apply(X2*Y,2,sum)
cor(Z1,Z2)
n=1000
nrep=10000
rho=0.2
X1 = matrix(rnorm(n*nrep),ncol=nrep)
X2 = 0.2*X1 + 0.8*matrix(rnorm(n*nrep),ncol=nrep)
Y = X1+X2+ 100*matrix(rnorm(n*nrep),ncol=nrep)
Z1 = apply(X1*Y, 2, sum)
Z2 = apply(X2*Y,2,sum)
cor(Z1,Z2)
n=1000
nrep=10000
rho=0.4
X1 = matrix(rnorm(n*nrep),ncol=nrep)
X2 = 0.2*X1 + 0.8*matrix(rnorm(n*nrep),ncol=nrep)
Y = X1+X2+ 100*matrix(rnorm(n*nrep),ncol=nrep)
Z1 = apply(X1*Y, 2, sum)
X1 = matrix(rnorm(n*nrep),ncol=nrep)
X2 = sqrt(rho)*X1 + sqrt(1-rho)*matrix(rnorm(n*nrep),ncol=nrep)
cor(X1[,1],X2[,1])
rho
cor(X1[,1],X2[,3])
cor(X1[,3],X2[,3])
cor(X1[,4],X2[,4])
cor(X1[,5],X2[,5])
sqrt(rho)
rho=0.2
X1 = matrix(rnorm(n*nrep),ncol=nrep)
X2 = (rho*X1 + (1-rho)*matrix(rnorm(n*nrep),ncol=nrep))/(rho^2 + (1-rho)^2)
apply(X2,2,sd)
apply(X1,2,sd)
apply(X2,2,var)
X2 = (rho*X1 + (1-rho)*matrix(rnorm(n*nrep),ncol=nrep))/sqrt(rho^2 + (1-rho)^2)
apply(X2,2,var)
apply(X2,2,sd)
Y = X1+X2+ 100*matrix(rnorm(n*nrep),ncol=nrep)
Z1 = apply(X1*Y, 2, sum)
Z2 = apply(X2*Y,2,sum)
cor(Z1,Z2)
Y = X1+X2+ matrix(rnorm(n*nrep),ncol=nrep)
Z1 = apply(X1*Y, 2, sum)
Z2 = apply(X2*Y,2,sum)
cor(Z1,Z2)
Y = X1+X2+ 1000*matrix(rnorm(n*nrep),ncol=nrep)
Z1 = apply(X1*Y, 2, sum)
Z2 = apply(X2*Y,2,sum)
cor(Z1,Z2)
apply(X1*X2,2,sum)
apply(X1*X2,2,sum)/1000
hist(apply(X1*X2,2,sum)/1000)
mean(apply(X1*X2,2,sum)/1000)
cor(Z1,X2)
cor(Z1,Z2)
apply(X1*X2,2,mean) # compute empirical correlation
mean(apply(X1*X2,2,mean)) # compute empirical (mean) correlation
cor(Z1,Z2)
lambda=1000
Y = X1+X2+ lambda*matrix(rnorm(n*nrep),ncol=nrep)
Z1 = apply(X1*Y, 2, sum)
Z2 = apply(X2*Y,2,sum)
cor(Z1,Z2)
mean(apply(X1*X2,2,mean)) # compute empirical (mean) correlation
lambda=10
Y = X1+X2+ lambda*matrix(rnorm(n*nrep),ncol=nrep)
Z1 = apply(X1*Y, 2, sum)
Z2 = apply(X2*Y,2,sum)
cor(Z1,Z2)
mean(apply(X1*X2,2,mean)) # compute empirical (mean) correlation
lambda=1
Y = X1+X2+ lambda*matrix(rnorm(n*nrep),ncol=nrep)
Z1 = apply(X1*Y, 2, sum)
Z2 = apply(X2*Y,2,sum)
cor(Z1,Z2)
mean(apply(X1*X2,2,mean)) # compute empirical (mean) correlation
lambda=seq(1,10,100,1000)
for(i in 1:length(lambda)){
Y = X1+X2+ lambda[i]*matrix(rnorm(n*nrep),ncol=nrep)
Z1 = apply(X1*Y, 2, sum)
Z2 = apply(X2*Y,2,sum)
print(cor(Z1,Z2),mean(apply(X1*X2,2,mean))) # compute empirical (mean) correlation of Z1,Z2 and X1,X2
n=1000
nrep=10000
rho=0.2
#set up columns of X1 and X2 to have correlation rho, variance 1
X1 = matrix(rnorm(n*nrep),ncol=nrep)
X2 = (rho*X1 + (1-rho)*matrix(rnorm(n*nrep),ncol=nrep))/sqrt(rho^2 + (1-rho)^2)
#actually doesn't quite work.. need to compute this correlation
lambda=c(1,10,100,1000)
for(i in 1:length(lambda)){
Y = X1+X2+ lambda[i]*matrix(rnorm(n*nrep),ncol=nrep)
Z1 = apply(X1*Y, 2, sum)
Z2 = apply(X2*Y,2,sum)
print(cor(Z1,Z2),mean(apply(X1*X2,2,mean))) # compute empirical (mean) correlation of Z1,Z2 and X1,X2
}
n=1000
}
n=1000
nrep=10000
rho=0.2
#set up columns of X1 and X2 to have correlation rho, variance 1
X1 = matrix(rnorm(n*nrep),ncol=nrep)
X2 = (rho*X1 + (1-rho)*matrix(rnorm(n*nrep),ncol=nrep))/sqrt(rho^2 + (1-rho)^2)
#actually doesn't quite work.. need to compute this correlation
lambda=c(1,10,100,1000)
for(i in 1:length(lambda)){
Y = X1+X2+ lambda[i]*matrix(rnorm(n*nrep),ncol=nrep)
Z1 = apply(X1*Y, 2, sum)
Z2 = apply(X2*Y,2,sum)
print(cor(Z1,Z2),mean(apply(X1*X2,2,mean))) # compute empirical (mean) correlation of Z1,Z2 and X1,X2
}
```
i=1
Y = X1+X2+ lambda[i]*matrix(rnorm(n*nrep),ncol=nrep)
Z1 = apply(X1*Y, 2, sum)
Z2 = apply(X2*Y,2,sum)
print(cor(Z1,Z2),mean(apply(X1*X2,2,mean))) # compute empirical (mean) correlation of Z1,Z2 and X1,X2
cor(Z1,Z2)
Y=matrix(rnorm(n*nrep),ncol=nrep)
X=matrix(rnorm(n*nrep),ncol=nrep)
mean(apply(Y*X,2,mean))
bhat = apply(Y*X,2,mean)
sd(bhat)
1/sqrt(1000)
sample_in
sample_int
?sampleint
?sample./int
?sample.int
fun(1:3, 1:4)
library(Rcpp)
library(inline)
src <- '
Rcpp::NumericVector xa(a);
Rcpp::NumericVector xb(b);
int n_xa = xa.size(), n_xb = xb.size();
Rcpp::NumericVector xab(n_xa + n_xb - 1);
for (int i = 0; i < n_xa; i++)
for (int j = 0; j < n_xb; j++)
xab[i + j] += xa[i] * xb[j];
return xab;
'
fun <- cxxfunction(signature(a = "numeric", b = "numeric"),src, plugin = "Rcpp")
fun(1:3, 1:4)
View(P)
load("debug_logLR_inf.Robj")
pwd
system("pwd")
source('~/.active-rstudio-document', echo=TRUE)
load("../paper/Rcode/sim1_out.RData") #load simulation results
setwd("~/Dropbox/Documents/git/ash/talks")
load("../paper/Rcode/sim1_out.RData") #load simulation results
load("../paper/Rcode/sim1.RData")
plot_pi0(list(simres1a))
source("../paper/Rcode/plot_pi0.R")
plot_pi0(list(simres1a))
get_pi0.ash
get_pi0(z.ash)
get_pi0.ash(z.ash)
library("ashr")
get_pi0.ash(z.ash)
ashr::get_pi0
get_pi0(z.ash)
plot_FDReg_hist(pval)
load("../scratchwork/Smemo_qbinom_zdat.RData")
# two-sided test
ttest.pval = function(t, df) {
pval = pt(t, df = df, lower.tail = T)
pval = 2 * ifelse(pval < 0.5, pval, 1 - pval)
return(pval)
}
tscore = zdat[3, ]/zdat[4, ]
pval = ttest.pval(tscore, df = 2)
qval = qvalue(pval)
highxp = xx>1000 # select high expressed genes
library(qvalue)
x = read.table(paste0("../../stat45800/data/nobrega/expression/counts.txt"), header = TRUE)
xx = rowSums(x[,2:5])
x = x[xx>0,]
xx = xx[xx>0]
highxp = xx>1000 # select high expressed genes
pval.high = pval[highxp]
qval.high = qvalue(pval.high)
qval.high
min(qval.high)
min(qval.high$qval)
zdat.ash$lfsr
%sfd
#sdf
zdat.ash
zdat
load("../scratchwork/Smemo_qbinom_zdat.RData")
zdat.ash = ash(zdat[3,],zdat[4,],df=2,method="fdr",mixcompdist="halfuniform")
hist(zdat[3,],main="Raw effect size estimates",xlab="betahat",xlim=c(-2,2),prob=T,ylim=c(0,3))
t=seq(-2,2,length=201)
lines(density(zdat.ash,t), col=2, lwd=2)
plot(zdat[3,],zdat.ash$PosteriorMean,main="Estimates vs Shrunken estimates",xlab="betahat",ylab="shrunk betahat",xlim=c(-2,2),ylim=c(-2,2),prob=T)
plot(zdat[3,],zdat.ash$PosteriorMean,main="Estimates vs Shrunken estimates",xlab="betahat",ylab="shrunk betahat",xlim=c(-2,2),ylim=c(-2,2))
warnings()
plot(zdat[3,],zdat.ash$PosteriorMean,main="Estimates vs Shrunken estimates",xlab="betahat",ylab="shrunk betahat",xlim=c(-2,2),ylim=c(-2,2))
zdat[3,]
zdat.ash$Posterior
names(zdat.ash)
zdat.ash$PosteriorMean
zdat.ash$g
zdat.ash$fitted
lines(density(zdat.ash,t), col=2, lwd=2)
density.ash
ashr:::density.ash
??ashr::dens
??ashr::dens.unimix
lines(cdf(zdat.ash,t), col=2, lwd=2)
cdf.as
cdf.ash
plot(cdf(zdat.ash,t), col=2, lwd=2)
plot(cdf.ash(zdat.ash,t), col=2, lwd=2)
zdat.ash$PosteriorMean
ash
zdat.ash$Negative
zdat.ash$Positive
z=rnorm(1000)
zz = ash(z,1,method="fdr",mixcompdist="uniform")
zz$PosteriorMean
install.packages("~/Dropbox/Documents/git/ash/package/ashr.tar.gz",type="source")
library(ashr)
zz = ash(z,1,method="fdr",mixcompdist="uniform")
zz$Posterior
zz$PosteriorMean
zz$fitted
require("ashr")
#simple simulated example
ncz = 100 # number of bins in z score histograms
set.seed(111)
hh.betahat = rnorm(1000,0,2)
hh.sebetahat = 1
hh.zscore = hh.betahat/hh.sebetahat
hh.pval = pchisq(hh.zscore^2,df=1,lower.tail=F)
hh.ash = ash(hh.betahat,hh.sebetahat, method="fdr")
hh.q = qvalue(hh.pval)
ash
.libPaths
.libPaths()
install.packages("../package/ashr.no.cxx.tar.gz")
install.packages("../package/ashr.no.cxx.tar.gz",type="source",repos=NULL)
require("ashr")
ncz = 100 # number of bins in z score histograms
set.seed(111)
hh.betahat = rnorm(1000,0,2)
hh.sebetahat = 1
hh.zscore = hh.betahat/hh.sebetahat
hh.pval = pchisq(hh.zscore^2,df=1,lower.tail=F)
hh.ash = ash(hh.betahat,hh.sebetahat, method="fdr")
?ash
ash
.libPaths()
require("ashr")
ash
#simple simulated example
ncz = 100 # number of bins in z score histograms
set.seed(111)
hh.betahat = rnorm(1000,0,2)
hh.sebetahat = 1
hh.zscore = hh.betahat/hh.sebetahat
hh.pval = pchisq(hh.zscore^2,df=1,lower.tail=F)
hh.ash = ash(hh.betahat,hh.sebetahat, method="fdr")
hh.q = qvalue(hh.pval)
source('~/.active-rstudio-document', echo=TRUE)
library("ashr")
?library
detach(unload=TRUE)
detach(ashr,unload=TRUE)
ash
library("ashr")
globalenv()
?ls
ls(envir=globalenv())
objects(envir=globalenv())
setwd("~/Dropbox/Documents/git/ash/talks")
load(".RData")
install.packages("../package/ashr.no.cxx.tar.gz")
install.packages("../package/ashr.no.cxx.tar.gz",repos="NULL",type="source")
install.packages("../package/ashr.no.cxx.tar.gz",type="source",repos=NULL)
output: ioslides_presentation
?call
do.call
?do.call
source('~/.active-rstudio-document', echo=TRUE)
plot(zdat[4,],zdat[3,])
plot(zdat[3,],zdat[3,]/zdat[4,])
plot(zdat[3,],abs(zdat[3,]/zdat[4,]))
plot(zdat[3,],abs(zdat[3,]/zdat[4,]),col=1+(zdat.ash$lfsr<0.05))
plot(zdat[3,],abs(zdat[3,]/zdat[4,]),col=1+(zdat.ash$lfsr<0.05),xlim=c(-1,1))
zdat.ash.ES = ash(zdat[3,],zdat[4,],df=2,method="fdr",mixcompdist="halfuniform", model="ES")
zdat.ash.ES$loglik
zdat.ash$loglik
zdat.ash.EEn = ash(zdat[3,],zdat[4,],df=2,method="fdr",mixcompdist="normal", model="EE")
zdat.ash.EEn = ash(zdat[3,],zdat[4,],df=2,method="fdr",mixcompdist="uniform", model="EE")
zdat.ash.EEn$loglik
zdat.ash$loglik
zdat.ash.ES$lfsr
min(zdat.ash.ES$lfsr)
plot(zdat[3,],abs(zdat[3,]/zdat[4,]),col=1+(zdat.ash.ES$lfsr<0.2),xlim=c(-2,2),xlab="beta-hat",ylab="zscore")
sum(is.na(zdat.ash.ES$lfsr))
sum(is.nan(zdat.ash.ES$lfsr))
plot(zdat[3,],abs(zdat[3,]/zdat[4,]),col=1+(zdat.ash.ES$lfsr<0.5),xlim=c(-2,2),xlab="beta-hat",ylab="zscore")
plot(zdat[3,],abs(zdat[3,]/zdat[4,]),col=1+(zdat.ash.ES$lfsr<0.2),xlim=c(-2,2),xlab="beta-hat",ylab="zscore")
which.max(abs(zdat[3,]/zdat[4,]))
zdat.ash.ES$lfsr[17217]
zdat.ash[17217,]
zdat.ash[3,17217]
zdat[3,17217]
zdat[4,17217]
lfsr
zdat.ash$ZeroProb[17217]
zdat.ash$NegativeProb[17217]
zdat.ash$PositiveProb[17217]
zdat.ash.ES$PositiveProb[17217]
zdat.ash.ES$ZeroProb[17217]
plot(zdat[3,]/zdat[4,],zdat.ash.ES$lfsr)
zdat.ash.ES$g
zdat.ash.ES$fitted.g
ashr:::compdens_conv_mixlik
ashr:::compdens_conv_unimix
ashr:::compdens_conv.unimix
g=zdat.ash.ES$fitted.g
ashr:::compcdf_post(g,0,-20,1,NULL)
ashr:::compcdf_post.unimix(g,0,-20,1,NULL)
ashr:::compdens_conv.unimix(g,0,-20,1,NULL)
ashr:::compdens_conv.unimix(g,0,-20,1,NULL,"+")
ashr:::compdens_conv.unimix(g,-10,1,NULL,"+")
ashr:::compdens_conv.unimix(g,-20,1,NULL,"+")
ashr:::dens_conv.unimix(g,-20,1,NULL,"+")
plot(ashr:::dens_conv.unimix(g,-20,1,NULL,"+"))
plot(ashr:::compdens_conv.unimix(g,-20,1,NULL,"+"))
g$mean[20]
g$m[20]
g$a[20]
g$b[20]
plot(ashr:::compcdf_post.unimix(g,0,-20,1,NULL))
comp_sd(g)==0
ashr:::comp_sd(g)==0
ashr:::comp_sd.unimix(g)==0
g$a[23]
g$b[23]
ashr:::dens_conv.unimix(g,-20,1,NULL,"+")[23]
ashr:::compdens_conv.unimix(g,-20,1,NULL,"+")[23]
ashr:::compdens_conv.unimix(g,-20,1,NULL,"+")[22]
ashr:::compdens_conv.unimix(g,-20,1,NULL,"+")[21]
plot(ashr:::compdens_conv.unimix(g,-20,1,NULL,"+"))
comppostprob(g,-20,1,NULL)
plot(comppostprob(g,-20,1,NULL))
g$a[17]
g$pi[17]
g$pi[18]
g$pi[16]
g$a[16]
g$a[19]
g$pi[19]
g$pi[20]
g$pi
zdat.ash$ZeroProb[17217]
zdat.ashES$ZeroProb[17217]
zdat.ash.ES$ZeroProb[17217]
zdat[17217,]
zdat[,17217]
zdat[3,17217]/zdat[4,17217]
plot(comppostprob(g,-42.09862,1,NULL))
plot(comppostprob(g,-42.09862,1,NULL)[comp_sd(g)==0])
comppostprob(g,-42.09862,1,NULL)[comp_sd(g)==0]
comppostprob(g,-42.09862,1,NULL)[comp_sd.unimix(g)==0]
comppostprob(g,-42.09862,1,NULL)[ashr:::comp_sd.unimix(g)==0]
ashr:::comppostprob(g,-42.09862,1,NULL)[ashr:::comp_sd.unimix(g)==0]
g=zdat.ash.ES$fitted.g
